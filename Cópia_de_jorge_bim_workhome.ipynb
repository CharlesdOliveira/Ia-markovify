{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CharlesdOliveira/Ia-markovify/blob/main/C%C3%B3pia_de_jorge_bim_workhome.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Instalação da biblioteca**\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "n-EFyGGlsMpA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1jCCFWVr3gt",
        "outputId": "cb85b2f7-3a4f-465c-b938-57caba8b8fee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting markovify\n",
            "  Downloading markovify-0.9.4.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting unidecode (from markovify)\n",
            "  Downloading Unidecode-1.3.8-py3-none-any.whl.metadata (13 kB)\n",
            "Downloading Unidecode-1.3.8-py3-none-any.whl (235 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/235.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: markovify\n",
            "  Building wheel for markovify (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for markovify: filename=markovify-0.9.4-py3-none-any.whl size=18607 sha256=923fa142f4b60fd3affd7657ff4a97141c98f680ad67811f3fbc861019d8b49c\n",
            "  Stored in directory: /root/.cache/pip/wheels/ca/8c/c5/41413e24c484f883a100c63ca7b3b0362b7c6f6eb6d7c9cc7f\n",
            "Successfully built markovify\n",
            "Installing collected packages: unidecode, markovify\n",
            "Successfully installed markovify-0.9.4 unidecode-1.3.8\n"
          ]
        }
      ],
      "source": [
        "!pip install markovify #Instalação da biblioteca"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Código com a IA**"
      ],
      "metadata": {
        "id": "ZFTOvwAsphEp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Lendo um arquivo .txt, fazendo a variável receber esse arquivo como string**\n",
        "\n"
      ],
      "metadata": {
        "id": "RB3paqtSsYq2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importando agora a blibioteca para conseguir usar sem erros\n",
        "import markovify\n",
        "\n",
        "text = \"eu gosto de andar as vezes,eu gosto de comer, eu gosto de dormir\"\n",
        "#definindo o texto ja\n",
        "\n",
        "with open(\"nome.txt\",\"w\") as f:\n",
        "    f.write(text)#salva o texto\n",
        "\n",
        "#gerando um modelo de texto atraves do \"Nome.text com as palavras ja dentro do bloco de notas\"\n",
        "modelotexto = markovify.Text(text,state_size=1)\n",
        "\n",
        "# Gerar uma frase aleatória\n",
        "frase = modelotexto.make_sentence()\n",
        "print(frase)\n",
        "\n",
        "\n",
        "\n",
        "# Verificar se o texto está em formato de string e corrigi, se necessário\n",
        "if not isinstance(text, str):\n",
        "    if isinstance(text, (list, tuple)):\n",
        "        texto = \" \".join(text)  # Converte lista/tuple para string\n",
        "    else:\n",
        "        raise ValueError(\"O texto carregado não está em um formato reconhecido.\")\n",
        "\n",
        "\n",
        "#gera uma  frase com palavras iniciais específicas\n",
        "# Usa um início específico ex: eu gosto\n",
        "import markovify #importando agora a blibioteca para conseguir usar sem erros\n",
        "\n",
        "with open(\"nome.txt\") as f:\n",
        "    text = f.read() # Lê o conteúdo do arquivo e o armazena na variável 'texto'\n",
        "\n",
        "\n",
        "#gera uma  frase com palavras iniciais específicas\n",
        "frasei = 'eu'\n",
        "# como a biblioteca da markovify ja nao preve diretamente,podemos sugerir próximas palavras gerando frases baseadas no contexto atual por exemplo:\n",
        "#verificar se foi digitado maiusculo ou minusculo\n",
        "if frasei.lower() in text.lower():\n",
        "\n",
        "    try:\n",
        "        # Gerar uma continuação para a frase inicial\n",
        "        completar_frase = modelotexto.make_sentence_with_start(frasei, strict=False)\n",
        "        print(\"Frase gerada:\", completar_frase)\n",
        "    except KeyError:\n",
        "        # Tratar caso o modelo não consiga prever com a frase inicial\n",
        "        print(f\"Não foi possível gerar uma continuação para: '{frasei}'\")\n",
        "else:\n",
        "    # Caso a frase inicial não esteja no texto de treinamento\n",
        "    print(f\"A sequência inicial '{frasei}' não foi encontrada no texto de treinamento.\")\n",
        "\n",
        "#Gerar frases com início específico\n",
        "\n",
        "#frase_inicial = \"eu ando \": Define a sequência inicial de palavras que será usada para começar a frase.\n",
        "#modelo.make_sentence_with_start(frasei, strict=False): Gera uma frase que começa com frase_inicial.\n",
        "# O parâmetro strict=False permite que o modelo use variações dessa sequência caso não encontre uma correspondência exata.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Qrro2dhUsahu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "193a81d2-c75a-4aaf-8e77-20b6996be1fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eu gosto de comer, eu gosto de comer, eu gosto de dormir\n",
            "Frase gerada: eu gosto de comer, eu gosto de comer, eu gosto de comer, eu gosto de andar as vezes,eu gosto de dormir\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Nr_7_F5dvpUm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**gerando texto e criando modelos**\n"
      ],
      "metadata": {
        "id": "WsOO1UbwqgHt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from markovify import NewlineText\n",
        "\n",
        "#gerando textos agora\n",
        "texto = \"\"\"\n",
        "eu gosto de andar\n",
        "eu gosto as vezes\n",
        "as vezes eu gosto\n",
        "as vezes eu gosto de dormir\n",
        "eu gosto de dormir\n",
        "eu gosto de comer\n",
        "as vezes eu gosto de comer\n",
        "eu gosto de comer as vezes\n",
        "eu gosto de dormir as vezes\n",
        "\"\"\"\n",
        "\n",
        "frase_inicial = \"eu\"\n",
        "# criando um modelo de texto que aumenta 2 palavras de contexto\n",
        "modelo_contexto = NewlineText(texto, state_size=2)\n",
        "texto_modificado = \"\\n\".join([f\" {linha}\" if not linha.startswith(frase_inicial) else linha for linha in texto.split(\"\\n\") if linha])\n",
        "modelo_contexto = NewlineText(texto_modificado, state_size=2)\n",
        "# Prever próximas palavras com base em uma sequência inicial\n",
        "previsao = modelo_contexto.make_sentence_with_start(frase_inicial, strict=False)\n",
        "print(previsao)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SFKnMHmuusG",
        "outputId": "8b4550b6-4234-4420-f6fe-70c16bd609b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eu gosto de comer as vezes eu gosto as vezes eu gosto\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a5OSGsOEtWem"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TpwfLysON2OF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Explicação da biblioteca** #\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xuqa16wNuicj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Markovify** é uma biblioteca em Python que utiliza cadeias de Markov para gerar textos aleatórios baseados em um corpus fornecido. Ela é muito utilizada em projetos criativos, como geração de conteúdo automatizado ou simulação de estilos de escrita. O funcionamento básico consiste em treinar o modelo com um texto inicial e, em seguida, usar as funções disponíveis para criar novas frases.\n",
        "\n",
        "Um dos métodos principais da biblioteca é o **markovify.Text(corpus)**, que cria o modelo a partir de um texto fornecido como string. Após criar o modelo, você pode gerar frases com **make_sentence()**, que retorna uma frase gerada aleatoriamente. Se desejar restringir o tamanho das frases, pode usar o método **make_short_sentence(max_chars)**, que limita o número máximo de caracteres na saída.\n",
        "\n",
        "Outros recursos úteis incluem **model.compile()**, que torna o modelo mais eficiente para reutilização, e **markovify.combine(models, [weights])**, que permite combinar diferentes modelos de texto com pesos específicos. Além disso, é possível acessar a estrutura interna do modelo por meio do atributo model.chain, ideal para personalizações avançadas.\n",
        "\n",
        "Essa biblioteca é poderosa, mas ao mesmo tempo simples de usar, tornando-se uma escolha popular para projetos que envolvem geração de texto criativo e análise de padrões de linguagem.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Y44LQ_8bux3e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explicação do Código:\n",
        "1.\tImportação da biblioteca markovify:\n",
        "o\tA biblioteca markovify é usada para gerar frases com base em um modelo de Markov. Ela permite que você crie um modelo de linguagem que pode gerar novas frases que soam coerentes com um texto de entrada.\n",
        "2.\tDefinir e salvar o texto no arquivo nome.txt:\n",
        "o\tVocê define um texto simples text = \"eu gosto de andar as vezes, eu gosto de comer, eu gosto de dormir\".\n",
        "o\tEsse texto é salvo no arquivo nome.txt usando o bloco de código:\n",
        "python\n",
        "Copiar código\n",
        "with open(\"nome.txt\", \"w\") as f:\n",
        "    f.write(text)\n",
        "3.\tCriando o modelo de Markov:\n",
        "o\tO texto carregado é usado para criar um modelo de Markov:\n",
        "python\n",
        "Copiar código\n",
        "modelotexto = markovify.Text(text, state_size=1)\n",
        "o\tEsse modelo pode ser usado para gerar frases aleatórias baseadas no texto de entrada.\n",
        "4.\tGerar uma frase aleatória:\n",
        "o\tO modelo gerado pode criar frases aleatórias com modelotexto.make_sentence():\n",
        "python\n",
        "Copiar código\n",
        "frase = modelotexto.make_sentence()\n",
        "print(frase)\n",
        "o\tIsso gerará uma frase com base nas palavras do texto carregado.\n",
        "5.\tVerificação de formato do texto:\n",
        "o\tVerifica se o texto carregado está em formato de string. Se não estiver, converte listas ou tuplas para uma string:\n",
        "python\n",
        "Copiar código\n",
        "if not isinstance(text, str):\n",
        "    if isinstance(text, (list, tuple)):\n",
        "        text = \" \".join(text)\n",
        "    else:\n",
        "        raise ValueError(\"O texto carregado não está em um formato reconhecido.\")\n",
        "6.\tLer novamente o texto do arquivo nome.txt:\n",
        "o\tVocê lê novamente o texto de nome.txt:\n",
        "python\n",
        "Copiar código\n",
        "with open(\"nome.txt\") as f:\n",
        "    text = f.read()\n",
        "7.\tGerar uma frase com uma sequência inicial específica (frasei):\n",
        "o\tVocê define uma sequência inicial de palavras (frasei = 'eu') e tenta gerar uma frase que comece com essa sequência:\n",
        "python\n",
        "Copiar código\n",
        "frasei = 'eu'\n",
        "if frasei.lower() in text.lower():\n",
        "    try:\n",
        "        completar_frase = modelotexto.make_sentence_with_start(frasei, strict=False)\n",
        "        print(\"Frase gerada:\", completar_frase)\n",
        "    except KeyError:\n",
        "        print(f\"Não foi possível gerar uma continuação para: '{frasei}'\")\n",
        "else:\n",
        "    print(f\"A sequência inicial '{frasei}' não foi encontrada no texto de treinamento.\")\n",
        "o\tVerificação de maiúsculas e minúsculas: A busca pela sequência inicial é feita sem distinguir entre maiúsculas e minúsculas (frasei.lower() in text.lower()).\n",
        "o\tGerar continuação da frase: O modelo tenta gerar uma continuação para a sequência inicial com make_sentence_with_start(frasei, strict=False). O parâmetro strict=False permite que o modelo use variações da sequência inicial, caso não encontre uma correspondência exata.\n",
        "\n"
      ],
      "metadata": {
        "id": "w27rdbXj8w1N"
      }
    }
  ]
}